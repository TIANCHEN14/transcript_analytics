{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776ae76a-781b-4481-a702-5d804ddeec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "# transcribing audio that is \n",
    "def transcribe_audio(audio_array, model, processor):\n",
    "    # transcrible audio using whisper model\n",
    "    #print(\"transcribe function called\")\n",
    "\n",
    "    #print(\"Array shape : \" , audio_array.shape)\n",
    "    #print(\"Array type : \" , audio_array.dtype)\n",
    "\n",
    "    # MAKE SURE THE DATA IS IN AN 1D ARRAY BEFORE PASS IT IN\n",
    "    inputs = processor(audio_array , sampling_rate = 16000 , return_tensors = 'pt').input_features\n",
    "    inputs = inputs.to('cuda')\n",
    "    \n",
    "    #print(\"start to transcrpting\")\n",
    "    \n",
    "    # generated new ids base on the inputs\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(inputs)\n",
    "    \n",
    "    # Decode tokens\n",
    "    output_text = processor.batch_decode(output_ids, skip_special_tokens = True)\n",
    "    \n",
    "    return output_text[0]\n",
    "    \n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    # Append the incoming audio data to the global list\n",
    "    global audio_data\n",
    "    audio_data.append(indata.copy())  \n",
    "\n",
    "def record_audio(duration = 5 , model = None, processor = None):\n",
    "    # define global variable for all audio samples\n",
    "    global audio_data\n",
    "    audio_data = []\n",
    "    \n",
    "    # define sampling rate\n",
    "    sampling_rate = 16000\n",
    "    channels = 1 # mono channels\n",
    "    \n",
    "    # Start the stream\n",
    "    with sd.InputStream(callback=audio_callback, samplerate=sampling_rate, channels=channels):\n",
    "        sd.sleep(duration * 1000)  # Sleep for the duration of the recording\n",
    "\n",
    "\n",
    "    audio_array = np.concatenate(audio_data)\n",
    "    audio_array = audio_array.squeeze()\n",
    "    transcription = transcribe_audio(audio_array, model, processor)\n",
    "    \n",
    "    sd.wait()\n",
    "    return transcription\n",
    "\n",
    "    #return audio_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e68ca7-8b26-4e4a-bd2d-b0506c495e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-medium.en\").to('cuda')\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium.en\")\n",
    "\n",
    "sd.default.samplerate = 16000\n",
    "sd.default.device = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090b3fd-29ce-4612-8526-58ce57c87b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chent\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:697: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording completed. Transcription:  Hey Charlotte!\n",
      "###################################################################################################################\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    #print(\"Starting a new 10-second recording...\")\n",
    "    transcription = record_audio(5, model=model, processor=processor)\n",
    "    print(\"Recording completed. Transcription:\", transcription)\n",
    "    print(\"###################################################################################################################\")\n",
    "    #print(\"Waiting for the next recording...\")\n",
    "    sd.sleep(10)  # Delay before the next recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace9f1c-ab0e-4df0-abe9-6299c155e374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
