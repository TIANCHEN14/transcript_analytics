{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbeeaeb-66c5-4dae-887b-5849f40761c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251bad51-7967-4d03-a798-aa3728c781f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-medium.en\").to('cuda')\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "300c2981-2ea4-4994-b526-ab42c8b2444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.default.samplerate = 16000\n",
    "sd.default.device = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28f7f4-c26d-4d8c-9e27-2124f8da2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_array, model, processor):\n",
    "    # transcrible audio using whisper model\n",
    "    print(\"transcribe function called\")\n",
    "    \n",
    "    inputs = processor(audio_array , sampling_rate = 16000 , return_tensors = 'pt')\n",
    "    inputs = inputs.to('cuda')\n",
    "    \n",
    "    print(\"start to transcrpting\")\n",
    "    \n",
    "    # generated new ids base on the inputs\n",
    "    output_ids = model.generate(inputs)\n",
    "    \n",
    "    # Decode tokens\n",
    "    output_text = processor.batch_decode(output_ids, skip_special_tokens = True)\n",
    "    \n",
    "    return output_text[0]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09fc4f2a-19a4-4dab-a5c7-e5ea3345b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    # Append the incoming audio data to the global list\n",
    "    global audio_data\n",
    "    audio_data.append(indata.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8048752e-110d-42e5-9c75-05ceed972126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def record_audio(duration = 5 , model = None, processor = None):\n",
    "    # define global variable for all audio samples\n",
    "    global audio_data\n",
    "    audio_data = []\n",
    "    \n",
    "    # define sampling rate\n",
    "    sampling_rate = 16000\n",
    "    channels = 1 # mono channels\n",
    "    \n",
    "    # Start the stream\n",
    "    with sd.InputStream(callback=audio_callback, samplerate=sampling_rate, channels=channels):\n",
    "        sd.sleep(duration * 1000)  # Sleep for the duration of the recording\n",
    "\n",
    "    audio_array = np.concatenate(audio_data)\n",
    "    audio_array = audio_array.squeeze()\n",
    "    transcription = transcribe_audio(audio_array, model, processor)\n",
    "    \n",
    "    sd.wait()\n",
    "    #transcription = transcribe_audio(record, model, processor)\n",
    "    return transcription\n",
    "\n",
    "    #return audio_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d71f3c4-5ef8-443f-8847-8b05de122f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transcription = record_audio(5, model=model, processor=processor)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(transcription)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa65073-6cfd-4ccd-a921-ee586c3353bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcruble function called\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\feature_extraction_utils.py:182\u001b[0m, in \u001b[0;36mBatchFeature.convert_to_tensors\u001b[1;34m(self, tensor_type)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[1;32m--> 182\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m tensor\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\feature_extraction_utils.py:159\u001b[0m, in \u001b[0;36mBatchFeature._get_is_as_tensor_fns.<locals>.as_tensor\u001b[1;34m(value, dtype)\u001b[0m\n\u001b[0;32m    158\u001b[0m         value \u001b[38;5;241m=\u001b[39m as_tensor([np\u001b[38;5;241m.\u001b[39masarray(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m value], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 142. GiB for an array with shape (79456, 480000, 1) and data type float32",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trans \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranscription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[1;34m(audio_array, model, processor)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio\u001b[39m(audio_array, model, processor):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# transcrible audio using whisper model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscruble function called\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_array\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minput_features\n\u001b[0;32m      6\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart to transcrpting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\whisper\\processing_whisper.py:70\u001b[0m, in \u001b[0;36mWhisperProcessor.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to specify either an `audio` or `text` input to process.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\whisper\\feature_extraction_whisper.py:251\u001b[0m, in \u001b[0;36mWhisperFeatureExtractor.__call__\u001b[1;34m(self, raw_speech, truncation, pad_to_multiple_of, return_tensors, return_attention_mask, padding, max_length, sampling_rate, do_normalize, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m batched_speech \u001b[38;5;241m=\u001b[39m BatchFeature({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: raw_speech})\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# convert into correct format for padding\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m padded_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched_speech\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdo_normalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# zero-mean and unit-variance normalization\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_normalize:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\feature_extraction_sequence_utils.py:224\u001b[0m, in \u001b[0;36mSequenceFeatureExtractor.pad\u001b[1;34m(self, processed_features, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors)\u001b[0m\n\u001b[0;32m    221\u001b[0m             value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    222\u001b[0m         batch_outputs[key]\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchFeature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\feature_extraction_utils.py:78\u001b[0m, in \u001b[0;36mBatchFeature.__init__\u001b[1;34m(self, data, tensor_type)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, tensor_type: Union[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mstr\u001b[39m, TensorType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(data)\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\feature_extraction_utils.py:188\u001b[0m, in \u001b[0;36mBatchFeature.convert_to_tensors\u001b[1;34m(self, tensor_type)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing values of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 188\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    189\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate padding \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m         )\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length."
     ]
    }
   ],
   "source": [
    "trans = transcribe_audio(transcription, model, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c833942-2c08-4972-9d40-96ccb917417f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting a new 10-second recording...\n",
      "transcruble function called\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting a new 10-second recording...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     transcription \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecording completed. Transcription:\u001b[39m\u001b[38;5;124m\"\u001b[39m, transcription)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting for the next recording...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m, in \u001b[0;36mrecord_audio\u001b[1;34m(duration, model, processor)\u001b[0m\n\u001b[0;32m     12\u001b[0m     sd\u001b[38;5;241m.\u001b[39msleep(duration \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)  \u001b[38;5;66;03m# Sleep for the duration of the recording\u001b[39;00m\n\u001b[0;32m     14\u001b[0m audio_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(audio_data)\n\u001b[1;32m---> 15\u001b[0m transcription \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m sd\u001b[38;5;241m.\u001b[39mwait()\n\u001b[0;32m     18\u001b[0m transcription \u001b[38;5;241m=\u001b[39m transcrible_audio(record, model, processor)\n",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[1;34m(audio_array, model, processor)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio\u001b[39m(audio_array, model, processor):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# transcrible audio using whisper model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscruble function called\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_array\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minput_features\n\u001b[0;32m      6\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart to transcrpting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\whisper\\processing_whisper.py:70\u001b[0m, in \u001b[0;36mWhisperProcessor.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to specify either an `audio` or `text` input to process.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\whisper\\feature_extraction_whisper.py:251\u001b[0m, in \u001b[0;36mWhisperFeatureExtractor.__call__\u001b[1;34m(self, raw_speech, truncation, pad_to_multiple_of, return_tensors, return_attention_mask, padding, max_length, sampling_rate, do_normalize, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m batched_speech \u001b[38;5;241m=\u001b[39m BatchFeature({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: raw_speech})\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# convert into correct format for padding\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m padded_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched_speech\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdo_normalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# zero-mean and unit-variance normalization\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_normalize:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\feature_extraction_sequence_utils.py:209\u001b[0m, in \u001b[0;36mSequenceFeatureExtractor.pad\u001b[1;34m(self, processed_features, padding, max_length, truncation, pad_to_multiple_of, return_attention_mask, return_tensors)\u001b[0m\n\u001b[0;32m    206\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# padding\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncated_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m batch_outputs:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\feature_extraction_sequence_utils.py:281\u001b[0m, in \u001b[0;36mSequenceFeatureExtractor._pad\u001b[1;34m(self, processed_features, max_length, padding_strategy, pad_to_multiple_of, return_attention_mask)\u001b[0m\n\u001b[0;32m    277\u001b[0m         processed_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    278\u001b[0m             processed_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m], (\u001b[38;5;241m0\u001b[39m, difference)\n\u001b[0;32m    279\u001b[0m         )\n\u001b[0;32m    280\u001b[0m     padding_shape \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m0\u001b[39m, difference), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, difference)\n\u001b[1;32m--> 281\u001b[0m     processed_features[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequired_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_value\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_attention_mask:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\arraypad.py:808\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, width_pair, value_pair \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axes, pad_width, values):\n\u001b[0;32m    807\u001b[0m         roi \u001b[38;5;241m=\u001b[39m _view_roi(padded, original_area_slice, axis)\n\u001b[1;32m--> 808\u001b[0m         _set_pad_area(roi, axis, width_pair, value_pair)\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Do nothing as _pad_simple already returned the correct result\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print(\"Starting a new 10-second recording...\")\n",
    "    transcription = record_audio(5, model=model, processor=processor)\n",
    "    print(\"Recording completed. Transcription:\", transcription)\n",
    "    print(\"Waiting for the next recording...\")\n",
    "    sd.sleep(10)  # Delay before the next recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea105ac-f03a-4841-a452-43dba2cb8ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
